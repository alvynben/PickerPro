{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4afc26",
   "metadata": {},
   "source": [
    "# Takeaways from that dude's research (3 articles)\n",
    "\n",
    "1. Spatial clustering and centroid clustering are broken, relies on picker to self optimise within that coordinate, so doesn't help in complying to protocol strictly\n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e38495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import random as rand\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from ast import literal_eval\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5808f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 2.7.18 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/bin/python2 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('df_lines.csv')   #df_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_count(col_name):\n",
    "    return len(df[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of unique orders\n",
    "get_unique_count('OrderNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737eed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Num of unique Dates\n",
    "get_unique_count('DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7d3f5",
   "metadata": {},
   "source": [
    "## Check if each order has unique SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ordernum_col].value_counts()#.unique()\n",
    "freqs = df[ordernum_col].value_counts()\n",
    "num_orders_with_n_orderlines = Counter(freqs)\n",
    "print(num_orders_with_n_orderlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e30d6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mapping Order lines\n",
    "# df_nline = pd.DataFrame(df.groupby(['OrderNumber'])['SKU'].count())\n",
    "\n",
    "unique_order_nums = df[ordernum_col].unique()\n",
    "for uon in unique_order_nums:\n",
    "    this_order = df[df[ordernum_col] == uon]\n",
    "    print(len(this_order['SKU'].unique()))\n",
    "    print(len(this_order['SKU'].index))\n",
    "    \n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67244f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ff8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2304a77",
   "metadata": {},
   "source": [
    "## Let's assume we this whole list is for one day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31782b4e",
   "metadata": {},
   "source": [
    "## Let DATE just be the date order is confirmed, and create another column TIME_TO_PICK be the latest time to pick finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand(this_range):\n",
    "    return rand.randint(this_range[0], this_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f591638",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_time_col = \"TIME_TO_PICK\"\n",
    "ordernum_col = \"OrderNumber\"\n",
    "seed = 1234\n",
    "hour_range = (8,18)\n",
    "min_range = (0,59)\n",
    "ordernum_to_picktime = {}\n",
    "\n",
    "rand.seed(seed)\n",
    "\n",
    "for x in df[ordernum_col].unique():\n",
    "    rand_hour = get_rand(hour_range)\n",
    "    rand_min = get_rand(min_range)\n",
    "    ordernum_to_picktime[x] = dt.time(rand_hour, rand_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pick_time(x):\n",
    "    return ordernum_to_picktime[x[ordernum_col]]\n",
    "\n",
    "df[pick_time_col] = df.apply(get_pick_time,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a750f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3f618",
   "metadata": {},
   "source": [
    "# Create occupancy grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245815be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c94f5f6b",
   "metadata": {},
   "source": [
    "# #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c8318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Order lines\n",
    "df_nline = pd.DataFrame(df.groupby(['OrderNumber'])['SKU'].count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73211073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_lines(df_orderlines):\n",
    "    ''' Processing of dataframe '''\n",
    "    # Mapping Order lines\n",
    "    df_nline = pd.DataFrame(df_orderlines.groupby(['OrderNumber'])['SKU'].count())\n",
    "\n",
    "    # Lists\n",
    "    list_ord = list(df_nline.index.astype(int).values)\n",
    "    list_lines = list(df_nline['SKU'].values.astype(int))\n",
    "\n",
    "    # Mapping\n",
    "    dict_nline = dict(zip(list_ord, list_lines))\n",
    "    df_orderlines['N_lines'] = df_orderlines['OrderNumber'].map(dict_nline)\n",
    "\n",
    "    # Processing\n",
    "    df_mono, df_multi = df_orderlines[df_orderlines['N_lines'] == 1], df_orderlines[df_orderlines['N_lines'] > 1]\n",
    "    del df_orderlines\n",
    "\n",
    "    return df_mono, df_multi\n",
    "\n",
    "mono, multi = process_lines(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderlines_mapping(df_orderlines, orders_number):\n",
    "\t'''Mapping orders with wave number'''\n",
    "\tdf_orderlines.sort_values(by='DATE', ascending = True, inplace = True)\n",
    "\t# Unique order numbers list\n",
    "\tlist_orders = df_orderlines.OrderNumber.unique()\n",
    "\tdict_map = dict(zip(list_orders, [i for i in range(1, len(list_orders))]))\n",
    "\t# Order ID mapping\n",
    "\tdf_orderlines['OrderID'] = df_orderlines['OrderNumber'].map(dict_map)\n",
    "\t# Grouping Orders by Wave of orders_number \n",
    "\tdf_orderlines['WaveID'] = (df_orderlines.OrderID%orders_number == 0).shift(1).fillna(0).cumsum()\n",
    "\t# Counting number of Waves\n",
    "\twaves_number = df_orderlines.WaveID.max() + 1\n",
    "\treturn df_orderlines, waves_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9db16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines, wave_num = orderlines_mapping(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c93b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(lines.OrderID%4 == 0).shift(1).fillna(0)#.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5c15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d12bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_locs = list(df['Coord'].apply(lambda t: literal_eval(t)).values)\n",
    "list_locs.sort()\n",
    "# List of unique coordinates\n",
    "[print(k) for k,_ in itertools.groupby(list_locs)]\n",
    "# list_locs = list(k for k,_ in itertools.groupby(list_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f12b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alley Coordinates on y-axis\n",
    "y_low, y_high = 5.5, 50\n",
    "# Origin Location\n",
    "origin_loc = [0, y_low]\n",
    "df_waves, df_results = simulate_batch(1, 10, y_low, y_high, origin_loc, 1000, df) #num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a434cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
    "                              'Parrot', 'Parrot'],\n",
    "                   'Max Speed': [380., 370., 24., 26.]})\n",
    "\n",
    "test.groupby(['Animal'])\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4115b0",
   "metadata": {},
   "source": [
    "## Methodology of experimentation\n",
    "1. Shuffle the locations of SKUs as it may be skewed to SKUs too near or too far from the starting point. Alternatively, swap the starting point from bottom left to top right.\n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1b4eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355f2827",
   "metadata": {},
   "source": [
    "## Group orders by First Come First serve \n",
    "\n",
    "## Constraints\n",
    "1. Whole number of invoice\n",
    "\n",
    "## Assumptions\n",
    "1. N = 10, should it even be necessary? \n",
    "2. I can sort the DATE field, which is when the order that must be fulfilled by \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce45fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "pallet_size = {\n",
    "    \"w\": 100,\n",
    "    \"l\": 120\n",
    "}\n",
    "def dict2df(cur_dict,cols):\n",
    "    cur_df = pd.DataFrame(columns = cols)\n",
    "    for k,v in cur_dict.items():\n",
    "        cur_df = pd.concat([cur_df,v])\n",
    "    return cur_df\n",
    "def sortOrdersFCFS(df):\n",
    "    col = 'OrderNumber'\n",
    "    unique_orders = df[col].unique()\n",
    "    print(unique_orders)\n",
    "    order_num_to_lines = {}\n",
    "    for uon in unique_orders:\n",
    "        order_num_to_lines[uon] = df[df[col] == uon]\n",
    "#     print(order_num_to_lines)\n",
    "    \n",
    "    return dict2df(order_num_to_lines, df.columns), order_num_to_lines#pd.DataFrame.from_dict(order_num_to_lines,orient='index')\n",
    "\n",
    "def total_area_lines(lines):\n",
    "    total_area = 0\n",
    "#     print(lines)\n",
    "#     print(type(lines))\n",
    "    for idx, line in lines.iterrows():\n",
    "#         print(line)\n",
    "        w = line[\"Size\"][0] / 10\n",
    "        l = line[\"Size\"][1] / 10\n",
    "        qty = line[\"PCS\"]\n",
    "        area = w * l * qty\n",
    "        total_area += area\n",
    "    return total_area\n",
    "\n",
    "def batch_FCFS(otld,n_max = 100):#otld df\n",
    "    \"\"\"returns a list of batches, each batch is a list of order numbers\"\"\"\n",
    "    on_col = 'OrderNumber'\n",
    "    unique_orders = df[on_col].unique()\n",
    "#     batch_id = 0\n",
    "    batch_list = []\n",
    "    cur_batch = [] # order numbers only\n",
    "    cur_size = 0\n",
    "    max_size = pallet_size[\"w\"] * pallet_size[\"l\"]\n",
    "    for uon in unique_orders:\n",
    "        lines = otld[uon] #df[df[on_col] == uon]\n",
    "        order_area = total_area_lines(lines)\n",
    "#         print(f'order_area: {order_area}')\n",
    "        if (cur_size + order_area) > max_size or len(cur_batch) >= n_max:\n",
    "            # Num of orders in batch\n",
    "            print(len(cur_batch))\n",
    "            batch_list.append(cur_batch)\n",
    "            cur_size = 0\n",
    "            cur_batch = []\n",
    "            continue\n",
    "        cur_batch.append(uon)\n",
    "        cur_size += order_area\n",
    "    \n",
    "    # NUM OF BATCHES\n",
    "    print(len(batch_list))\n",
    "    return batch_list\n",
    "\n",
    "def batch_SINGLE_ORDER():\n",
    "    on_col = 'OrderNumber'\n",
    "    unique_orders = df[on_col].unique()\n",
    "    return [[x] for x in unique_orders]\n",
    "\n",
    "def coords_str_to_list(df, col):\n",
    "    return list(df[col].apply(lambda t: literal_eval(t)).values)\n",
    "\n",
    "def gen_SKU_dict(df):\n",
    "#     df['SKU']\n",
    "    sku_dict = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        this_SKU = row['SKU']\n",
    "        sku_dict[this_SKU] = row[['Size','Coord','AlleyCell','Alley_Number','Location']]\n",
    "    return sku_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coord'] = coords_str_to_list(df,'Coord')\n",
    "df['Size'] = coords_str_to_list(df,'Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6efbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_sorted_df,order_to_lines_dict = sortOrdersFCFS(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8918c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_list = batch_FCFS(order_to_lines_dict,10)\n",
    "batch_list = batch_SINGLE_ORDER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bfeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_sku_df = df.sort_values(by='SKU')\n",
    "sku_dict = gen_SKU_dict(sorted_df)  #sku_dict[230976]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_low, y_high = 5.5, 50\n",
    "def get_walk_dist(p1,p2):\n",
    "    \"\"\"Cur assumption, floorplan is a simple layout of rows\"\"\"\n",
    "    # Start Point\n",
    "    x1, y1 = p1[0], p1[1]\n",
    "    # End Point\n",
    "    x2, y2 = p2[0], p2[1]\n",
    "    # Distance x-axis\n",
    "    distance_x = abs(x2 - x1)\n",
    "    # Distance y-axis\n",
    "    if x1 == x2:\n",
    "        distance_y1 = abs(y2 - y1)\n",
    "        distance_y2 = distance_y1\n",
    "    else:\n",
    "        distance_y1 = y_high - y1 + y_high - y2\n",
    "        distance_y2 = (y1 - y_low) + (y2 - y_low)\n",
    "    # Minimum distance on y-axis \n",
    "    distance_y = min(distance_y1, distance_y2)\n",
    "    # Total distance\n",
    "    distance = distance_x + distance_y\n",
    "    return int(distance)\n",
    "def zig_zag_routing(list_locs, cur_pos):\n",
    "    \"\"\"Just returns the distance following zig zag\"\"\"\n",
    "    \n",
    "    total_dist = 0\n",
    "    for loc in list_locs:\n",
    "        total_dist += get_walk_dist(cur_pos, loc)\n",
    "        cur_pos = loc\n",
    "    return total_dist\n",
    "\n",
    "# def zig_zag_routing_w_sku(sku_df, cur_pos):\n",
    "#     \"\"\"Returns total zig zag distance + walking distance per SKU\"\"\"\n",
    "    \n",
    "#     total_dist = 0\n",
    "#     for loc in list_locs:\n",
    "#         total_dist += get_walk_dist(cur_pos, loc)\n",
    "#         cur_pos = loc\n",
    "#     return total_dist\n",
    "\n",
    "\n",
    "def sort_locations(list_locs):\n",
    "    return sorted(list_locs)\n",
    "\n",
    "def sort_loc_df(sku_df):\n",
    "#     print(sku_df.head())\n",
    "#     print(sku_df['Coord'])\n",
    "    return sku_df.sort_values(by=\"Coord\")\n",
    "\n",
    "#sku 2 dist\n",
    "\n",
    "def get_sku_piece_counts(otld):\n",
    "    on_col = 'OrderNumber'\n",
    "    unique_orders = df[on_col].unique()\n",
    "    sku_pieces = {}\n",
    "    for uon in unique_orders:\n",
    "        for idx, row in otld[uon].iterrows():\n",
    "            cur_sku = row['SKU']\n",
    "            if cur_sku in sku_pieces:\n",
    "                sku_pieces[cur_sku] += row[\"PCS\"]\n",
    "            else:\n",
    "                sku_pieces[cur_sku] = row[\"PCS\"]\n",
    "    return sku_pieces\n",
    "\n",
    "def get_total_walking_dist(batch_list,otld,sku_dict): #batch\n",
    "    cur_positions = [[0, 5.5], [100, y_high]]\n",
    "    total_dists = []\n",
    "    batch_dists = []\n",
    "    for cur_pos in cur_positions:\n",
    "        total_dist = 0\n",
    "        for batch in batch_list:\n",
    "            list_locs = []\n",
    "            skus = set()\n",
    "            for order_num in batch:\n",
    "                for idx, line in otld[order_num].iterrows():\n",
    "                    skus.add(line['SKU'])\n",
    "            for sku in skus:\n",
    "                list_locs.append(sku_dict[sku]['Coord'])\n",
    "            sorted_list_locs = sort_locations(list_locs)\n",
    "#             print(sorted_list_locs[:10])\n",
    "            batch_dist = zig_zag_routing(sorted_list_locs,cur_pos)\n",
    "            \n",
    "            batch_dists.append(batch_dist)\n",
    "            total_dist += batch_dist\n",
    "        print(f\"total_dist: {total_dist}\")\n",
    "        print(batch_dists[-10:])\n",
    "        total_dists.append(total_dist)\n",
    "    return sum(total_dists) / len(total_dists), batch_dists\n",
    "\n",
    "def get_walking_dist_per_sku(batch_list,otld,sku_dict): #batch\n",
    "    cur_positions = [[5.5, y_low], [50, y_high]]\n",
    "    total_dists = []\n",
    "    batch_dists = []\n",
    "    sku_dists = {}\n",
    "    for cur_pos in cur_positions:\n",
    "        total_dist = 0\n",
    "        for batch in batch_list:\n",
    "            list_locs = []\n",
    "            sku_df = pd.DataFrame()\n",
    "            skus = set()\n",
    "            for order_num in batch:\n",
    "                for idx, line in otld[order_num].iterrows():\n",
    "                    skus.add(line['SKU'])\n",
    "            for sku in skus:\n",
    "#                 sku_df = pd.concat([sku_df,sku_dict[sku]],axis=1)\n",
    "                sku_df = sku_df.append(sku_dict[sku],ignore_index=True)\n",
    "            sku_df = sort_loc_df(sku_df)\n",
    "            batch_dist = zig_zag_routing(sku_df['Coord'],cur_pos)\n",
    "            for sku in skus:\n",
    "                if sku in sku_dists:\n",
    "                    sku_dists[sku].append(batch_dist)\n",
    "                else:\n",
    "                    sku_dists[sku] = []\n",
    "            batch_dists.append(batch_dist)\n",
    "            total_dist += batch_dist\n",
    "        total_dists.append(total_dist)\n",
    "    return sum(total_dists) / len(total_dists), batch_dists, sku_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957148d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_total_dist, batch_dists = get_total_walking_dist(batch_list,order_to_lines_dict,sku_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481658f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_pieces = get_sku_piece_counts(order_to_lines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_total_dist, batch_dists,sku_dist = get_walking_dist_per_sku(batch_list,order_to_lines_dict,sku_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abe3cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dist_per_sku = {}\n",
    "for k,v in sku_dist.items():\n",
    "    dist_per_sku[k] = sum(v) / len(v)\n",
    "    \n",
    "# print(dist_per_sku)\n",
    "max_sku,min_sku = max(dist_per_sku, key=dist_per_sku.get),min(dist_per_sku, key=dist_per_sku.get)\n",
    "max_dist,min_dist = max(dist_per_sku.values()),min(dist_per_sku.values())\n",
    "print(f\"max_dist,min_dist: {max_dist},{min_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ef785",
   "metadata": {},
   "source": [
    "## Group order lines by 1 hour pick times, with N max order lines per group/so long as can fit on pallet\n",
    "\n",
    "## Constraints\n",
    "2. Size of SKU_size * pieces for each orderlines in the invoice(s) should fit on w * l pallet/trolley\n",
    "3. A single route fulfils ALL orderlines within the group\n",
    "\n",
    "\n",
    "\n",
    "### Current assumptions\n",
    "1. User can pick unlimited pieces of each SKU in the group (i.e. no piece limit, all same size)\n",
    "2. A warehouse workflow that orders are being delivered out throughout the day (e.g. certain ecommerce sub-operations)\n",
    "3. Order fulilment times assumed the time to be delivered out so that drivers can successfully deliver goods on time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5093ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb1870",
   "metadata": {},
   "source": [
    "# Group orders by spatial closeness of majority of goods\n",
    "\n",
    "## Constraints\n",
    "1. A group consists of integer number of invoices\n",
    "2. Size of SKU_size * pieces for each orderlines in the invoice(s) should fit on w * l pallet/trolley\n",
    "3. A single route fulfils ALL orderlines within the invoice(s) in the group\n",
    "\n",
    "## Assumption\n",
    "1. A picking flow where everything is packed in the day, only to be delivered the following morning. Hence all invoices share the same \"order fulfilment\"\n",
    "\n",
    "## Compare to\n",
    "1. Group orders by First Come First Serve (i.e. batch orders based on as-is order in system)\n",
    "2. \n",
    "\n",
    "# WHAT NOT TO DO\n",
    "1. No condensing the closest point of centroid. It's fake haha\n",
    "\n",
    "## Future considerations\n",
    "2. Priority tags\n",
    "3. Installments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a423c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_date(df,date):\n",
    "    return df[df['DATE'] == date]\n",
    "\n",
    "unique_dates = df['DATE'].unique()\n",
    "for u_d in unique_dates:\n",
    "    this_df = filter_by_date(df,u_d)\n",
    "    print(this_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51c545",
   "metadata": {},
   "source": [
    "# Group orderlines by spatial closeness of majority of goods\n",
    "\n",
    "## Constraints\n",
    "1. A single picker handles invoice(s) from start to finish, across 1 or more waves\n",
    "2. A group can consists of fraction of invoice(s) so long as it can be fulfilled by the end of the day and the waves are handled by the same picker\n",
    "3. Size of SKU_size * pieces for each orderlines in the invoice(s) should fit on w * l pallet/trolley\n",
    "\n",
    "## Assumption\n",
    "1. Pickers will have to stay throughout the entire shift, to completely fulfil their invoices for the day\n",
    "2. Any weight can be handled by the pallet and the picker\n",
    "\n",
    "## Compare to\n",
    "1. Above method\n",
    "2. Grouping by first come first serve\n",
    "3. Baseline one by one order\n",
    "\n",
    "## WHAT NOT TO DO\n",
    "1. No condensing the closest point of centroid. It's fake haha\n",
    "\n",
    "## Future considerations \n",
    "1. Priorities\n",
    "2. Installments\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed476c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b18573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab6c7c0",
   "metadata": {},
   "source": [
    "# Routing\n",
    "\n",
    "1. NCL\n",
    "2. Google OR TOols  #https://developers.google.com/optimization/introduction/python\n",
    "3. Zig zag, complete an aisle before proceeding to next aisle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40685f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df79ea45",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2645b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3be06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c569c10",
   "metadata": {},
   "source": [
    "## What to do in the future?\n",
    "\n",
    "1. Make a better map\n",
    "2. Look into weight/difficulty of moving from one point to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f936f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
